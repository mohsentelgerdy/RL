{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"policy iteration.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"YGkxVb6ZiooS","executionInfo":{"status":"ok","timestamp":1619591898212,"user_tz":-270,"elapsed":1120,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["from __future__ import print_function, division\n","from builtins import range\n","import numpy as np"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MHJyPkntiooY"},"source":["## make Gridworld"]},{"cell_type":"code","metadata":{"id":"ODVDiCW6iooZ","executionInfo":{"status":"ok","timestamp":1619591900522,"user_tz":-270,"elapsed":1184,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["\n","ACTION_SPACE = ('U', 'D', 'L', 'R')\n","\n","\n","class Grid:  # Environment\n","\n","    def __init__(self,rows,cols,start):\n","        self.rows = rows\n","        self.cols = cols\n","        self.i = start[0]\n","        self.j = start[1]\n","\n","    def set(self, rewards, actions):\n","\n","        self.rewards = rewards\n","        self.actions = actions\n","\n","    def set_state(self, s):\n","        self.i = s[0]\n","        self.j = s[1]\n","\n","    def current_state(self):\n","        return (self.i, self.j)\n","\n","    def is_terminal(self, s):\n","        return s not in self.actions\n","\n","    def get_next_state(self, s, a):\n","\n","    # this answers: where would I end up if I perform action 'a' in state 's'?\n","\n","        (i, j) = (s[0], s[1])\n","\n","    # if this action moves you somewhere else, then it will be in this dictionary\n","\n","        if a in self.actions[(i, j)]:\n","            if a == 'U':\n","                i -= 1\n","            elif a == 'D':\n","                i += 1\n","            elif a == 'R':\n","                j += 1\n","            elif a == 'L':\n","                j -= 1\n","        return (i, j)\n","\n","    def all_states(self):\n","        return set(self.actions.keys()) | set(self.rewards.keys())\n","\n","\n","\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJGi860BiooZ"},"source":["## Define Grid 3*4"]},{"cell_type":"code","metadata":{"id":"ngG2n45liooZ","executionInfo":{"status":"ok","timestamp":1619591908340,"user_tz":-270,"elapsed":1195,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["def standard_grid():\n","\n","  # .  .  .  1\n","  # .  x  . -1\n","  # s  .  .  .\n","\n","    grid = Grid(3, 4, (2, 0))\n","    rewards = {(0, 3): 1, (1, 3): -1}\n","    actions = {\n","        (0, 0): ('D', 'R'),\n","        (0, 1): ('L', 'R'),\n","        (0, 2): ('L', 'D', 'R'),\n","        (1, 0): ('U', 'D'),\n","        (1, 2): ('U', 'D', 'R'),\n","        (2, 0): ('U', 'R'),\n","        (2, 1): ('L', 'R'),\n","        (2, 2): ('L', 'R', 'U'),\n","        (2, 3): ('L', 'U'),\n","        }\n","    grid.set(rewards, actions)\n","    return grid"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8Je5kHoiooa"},"source":["## Display Grid"]},{"cell_type":"code","metadata":{"id":"0HbLMcGIiooa","executionInfo":{"status":"ok","timestamp":1619591914474,"user_tz":-270,"elapsed":1186,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["def print_values(V, g):\n","    for i in range(g.rows):\n","        print(\"---------------------------\")\n","        for j in range(g.cols):\n","            v = V.get((i, j), 0)\n","            if v >= 0:\n","                print(\" %.2f|\" % v, end=\"\")\n","            else:\n","                print(\"%.2f|\" % v, end=\"\")  \n","        print(\"\")\n","\n","\n","def print_policy(P, g):\n","    for i in range(g.rows):\n","        print(\"---------------------------\")\n","        for j in range(g.cols):\n","            a = P.get((i, j), \" \")\n","            print(\"  %s  |\" % a, end=\"\")\n","        print(\"\")\n"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"89iZ-aT7iooa"},"source":["## evaluate fix policy and find optimal value functions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKN9w7OAioob","executionInfo":{"status":"ok","timestamp":1619591930923,"user_tz":-270,"elapsed":1126,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}},"outputId":"3501c716-ffcb-4e93-893a-b58590c36e83"},"source":["grid = standard_grid()\n","\n","### fixed policy ###\n","policy = {}\n","for state in grid.actions.keys():\n","    policy[state] = np.random.choice(ACTION_SPACE)\n","print_policy(policy, grid)\n","\n","\n","    "],"execution_count":15,"outputs":[{"output_type":"stream","text":["---------------------------\n","  U  |  D  |  R  |     |\n","---------------------------\n","  L  |     |  U  |     |\n","---------------------------\n","  L  |  L  |  D  |  U  |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GP5IvlHiioob","executionInfo":{"status":"ok","timestamp":1619591957692,"user_tz":-270,"elapsed":1189,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}},"outputId":"6a4f5acd-3845-4e23-99df-9e6459b3d203"},"source":["# initialize V(s) = 0\n","V = {}\n","for s in grid.all_states():\n","    V[s] = 0\n","\n","print_values(V, grid)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["---------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n","---------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n","---------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_D_3O528iooc"},"source":["## Reward and Transition probability"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlwtZgEviooc","executionInfo":{"status":"ok","timestamp":1619591826584,"user_tz":-270,"elapsed":1553,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}},"outputId":"33312df7-1997-4012-a77b-d1635b9ed654"},"source":["transition_probs = {}\n","rewards = {}\n","\n","for row in range(grid.rows):\n","    for col in range(grid.cols):\n","        state = (row, col)\n","        if not grid.is_terminal(state):\n","            for action in ACTION_SPACE:\n","                next_state = grid.get_next_state(state, action)\n","                transition_probs[(state, action, next_state)] = 1\n","                if next_state in grid.rewards:\n","                    rewards[(state, action, next_state)] = grid.rewards[next_state]\n","\n","\n","print(rewards)\n","print(\"---------------\")\n","print(transition_probs)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{((0, 2), 'R', (0, 3)): 1, ((1, 2), 'R', (1, 3)): -1, ((2, 3), 'U', (1, 3)): -1}\n","---------------\n","{((0, 0), 'U', (0, 0)): 1, ((0, 0), 'D', (1, 0)): 1, ((0, 0), 'L', (0, 0)): 1, ((0, 0), 'R', (0, 1)): 1, ((0, 1), 'U', (0, 1)): 1, ((0, 1), 'D', (0, 1)): 1, ((0, 1), 'L', (0, 0)): 1, ((0, 1), 'R', (0, 2)): 1, ((0, 2), 'U', (0, 2)): 1, ((0, 2), 'D', (1, 2)): 1, ((0, 2), 'L', (0, 1)): 1, ((0, 2), 'R', (0, 3)): 1, ((1, 0), 'U', (0, 0)): 1, ((1, 0), 'D', (2, 0)): 1, ((1, 0), 'L', (1, 0)): 1, ((1, 0), 'R', (1, 0)): 1, ((1, 2), 'U', (0, 2)): 1, ((1, 2), 'D', (2, 2)): 1, ((1, 2), 'L', (1, 2)): 1, ((1, 2), 'R', (1, 3)): 1, ((2, 0), 'U', (1, 0)): 1, ((2, 0), 'D', (2, 0)): 1, ((2, 0), 'L', (2, 0)): 1, ((2, 0), 'R', (2, 1)): 1, ((2, 1), 'U', (2, 1)): 1, ((2, 1), 'D', (2, 1)): 1, ((2, 1), 'L', (2, 0)): 1, ((2, 1), 'R', (2, 2)): 1, ((2, 2), 'U', (1, 2)): 1, ((2, 2), 'D', (2, 2)): 1, ((2, 2), 'L', (2, 1)): 1, ((2, 2), 'R', (2, 3)): 1, ((2, 3), 'U', (1, 3)): 1, ((2, 3), 'D', (2, 3)): 1, ((2, 3), 'L', (2, 2)): 1, ((2, 3), 'R', (2, 3)): 1}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZzzYptNTiooc"},"source":["## Policy evaluation using bootstrapping"]},{"cell_type":"code","metadata":{"id":"vvw8sfi3iooc","executionInfo":{"status":"ok","timestamp":1619592076260,"user_tz":-270,"elapsed":1091,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["def evaluate_deterministic_policy(grid, policy, V=None):\n","    iteration = 0\n","    while True:\n","        for state in grid.all_states():\n","            if not grid.is_terminal(state):\n","                new_v = 0\n","                for action in ACTION_SPACE:\n","                    for next_state in grid.all_states():\n","                        #deteministic actions:\n","                        action_prob = 1 if policy.get(state) == action else 0\n","\n","                        r = rewards.get((state, action, next_state), 0)\n","                        new_v += action_prob * transition_probs.get((state, action, next_state), 0) * (r + 0.9 * V[next_state])\n","                        \n","\n","                V[state] = new_v\n","\n","\n","\n","        iteration = iteration+1\n","    #     print_values(V, grid)\n","    #     print(\"\\n\")\n","        if iteration == 25:\n","            break\n","\n","    \n","    return V\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlwn8lgPiood","executionInfo":{"status":"ok","timestamp":1619592216962,"user_tz":-270,"elapsed":1094,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}},"outputId":"1f75b54f-867a-42a8-9ab0-e8483185b96b"},"source":["itteration = 0\n","\n","# ### fixed policy ###\n","# policy = {\n","# (2, 0): 'U',\n","# (1, 0): 'U',\n","# (0, 0): 'R',\n","# (0, 1): 'R',\n","# (0, 2): 'R',\n","# (1, 2): 'R',# this is not optimal\n","# (2, 1): 'R',\n","# (2, 2): 'U',\n","# (2, 3): 'L',\n","# (1, 1): 'X',\n","# (1, 3): 'H',\n","# (0, 3): 'G'\n","# }\n","\n","while True:\n","    V = evaluate_deterministic_policy(grid, policy, V)\n","    is_policy_converged = True\n","    for state in grid.actions.keys():\n","        best_value = float('-inf')\n","        for action in ACTION_SPACE:\n","            v = 0\n","            #find action value\n","            for next_state in grid.all_states():\n","                r = rewards.get((state, action, next_state), 0)\n","                v += transition_probs.get((state, action, next_state), 0) * (r + 0.9 * V[next_state])\n","            if v > best_value:\n","                best_action = action\n","                best_value = v\n","    \n","        if best_action != policy[state]:\n","            is_policy_converged = False\n","        policy[state] = best_action\n","    \n","    if is_policy_converged:\n","        break\n","print_policy(policy, grid)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["---------------------------\n","  R  |  R  |  R  |     |\n","---------------------------\n","  U  |     |  U  |     |\n","---------------------------\n","  U  |  R  |  U  |  L  |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wn9um11riooe"},"source":[""],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"monte carlo policy evaluation.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"_K5s6YATlUGG","executionInfo":{"status":"ok","timestamp":1619592533297,"user_tz":-270,"elapsed":1330,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BolEH_hvlUGN"},"source":["## Grid world"]},{"cell_type":"code","metadata":{"id":"GIiP9tH8lUGO","executionInfo":{"status":"ok","timestamp":1619592534719,"user_tz":-270,"elapsed":827,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["ACTION_SPACE = ('U', 'D', 'L', 'R')\n","\n","\n","class Grid:  # Environment\n","\n","    def __init__(self,rows,cols,start):\n","        self.rows = rows\n","        self.cols = cols\n","        self.i = start[0]\n","        self.j = start[1]\n","\n","    def set(self, rewards, actions):\n","\n","        self.rewards = rewards\n","        self.actions = actions\n","\n","    def set_state(self, s):\n","        self.i = s[0]\n","        self.j = s[1]\n","\n","    def current_state(self):\n","        return (self.i, self.j)\n","\n","    def is_terminal(self, s):\n","        return s not in self.actions\n","    \n","    def move(self, action):\n","    # check if legal move first\n","        if action in self.actions[(self.i, self.j)]:\n","            if action == 'U':\n","                self.i -= 1\n","            elif action == 'D':\n","                self.i += 1\n","            elif action == 'R':\n","                self.j += 1\n","            elif action == 'L':\n","                self.j -= 1\n","        return self.rewards.get((self.i, self.j), 0)\n","\n","    def game_over(self):\n","        # returns true if game is over, else false\n","        # true if we are in a state where no actions are possible\n","        return (self.i, self.j) not in self.actions\n","\n","    def all_states(self):\n","        return set(self.actions.keys()) | set(self.rewards.keys())\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkm-T0BGlUGO"},"source":["## Standard Grid world"]},{"cell_type":"code","metadata":{"id":"CSKgAnaelUGO","executionInfo":{"status":"ok","timestamp":1619592541490,"user_tz":-270,"elapsed":989,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["def standard_grid():\n","\n","  # .  .  .  1\n","  # .  x  . -1\n","  # s  .  .  .\n","\n","    grid = Grid(3, 4, (2, 0))\n","    rewards = {(0, 3): 1, (1, 3): -1}\n","    actions = {\n","        (0, 0): ('D', 'R'),\n","        (0, 1): ('L', 'R'),\n","        (0, 2): ('L', 'D', 'R'),\n","        (1, 0): ('U', 'D'),\n","        (1, 2): ('U', 'D', 'R'),\n","        (2, 0): ('U', 'R'),\n","        (2, 1): ('L', 'R'),\n","        (2, 2): ('L', 'R', 'U'),\n","        (2, 3): ('L', 'U'),\n","        }\n","    grid.set(rewards, actions)\n","    return grid"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gw7zyKQGlUGP"},"source":["## Display Grid"]},{"cell_type":"code","metadata":{"id":"bMK0oZzulUGP","executionInfo":{"status":"ok","timestamp":1619592546637,"user_tz":-270,"elapsed":1103,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["def print_values(V, g):\n","    for i in range(g.rows):\n","        print(\"---------------------------\")\n","        for j in range(g.cols):\n","            v = V.get((i, j), 0)\n","            if v >= 0:\n","                print(\" %.2f|\" % v, end=\"\")\n","            else:\n","                print(\"%.2f|\" % v, end=\"\")  \n","        print(\"\")\n","\n","\n","def print_policy(P, g):\n","    for i in range(g.rows):\n","        print(\"---------------------------\")\n","        for j in range(g.cols):\n","            a = P.get((i, j), \" \")\n","            print(\"  %s  |\" % a, end=\"\")\n","        print(\"\")\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hbk9wzgTlUGP","executionInfo":{"status":"ok","timestamp":1619592565297,"user_tz":-270,"elapsed":993,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["SMALL_ENOUGH = 1e-5\n","GAMMA = 0.9\n","ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaYBDtvilUGQ","executionInfo":{"status":"ok","timestamp":1619592891657,"user_tz":-270,"elapsed":930,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}}},"source":["def play_game(grid, policy, max_steps=20):\n","    # returns a list of states and corresponding returns\n","\n","    # reset game to start at a random position\n","    # we need to do this, because given our current deterministic policy\n","    # we would never end up at certain states, but we still want to measure their value\n","    start_states = list(grid.actions.keys())\n","    start_idx = np.random.choice(len(start_states))\n","    grid.set_state(start_states[start_idx])\n","\n","    s = grid.current_state()\n","    states_and_rewards = [(s, 0)] # list of tuples of (state, reward)\n","    steps = 0\n","    while not grid.game_over():\n","        a = policy[s]\n","        r = grid.move(a)\n","        s = grid.current_state()\n","        states_and_rewards.append((s, r))\n","\n","        steps += 1\n","        if steps >= max_steps:\n","            break\n","    G = 0\n","\n","    states_and_returns = []\n","    first = True\n","    for s, r in reversed(states_and_rewards):\n","        # the value of the terminal state is 0 by definition\n","        # we should ignore the first state we encounter\n","        # and ignore the last G, which is meaningless since it doesn't correspond to any move\n","        if first:\n","            first = False\n","        else:\n","            states_and_returns.append((s, G))\n","  \n","        G = r + GAMMA*G\n","    states_and_returns.reverse() # we want it to be in order of state visited\n","    return states_and_returns"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CnF6rz4lUGQ","executionInfo":{"status":"ok","timestamp":1619592908974,"user_tz":-270,"elapsed":932,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}},"outputId":"b0ab63cc-e6a2-49d7-b9ac-bf8743ded1d8"},"source":["grid = standard_grid()\n","\n","# print rewards\n","print(\"rewards:\")\n","print_values(grid.rewards, grid)\n","\n","# state -> action\n","policy = {\n","(2, 0): 'U',\n","(1, 0): 'U',\n","(0, 0): 'R',\n","(0, 1): 'R',\n","(0, 2): 'R',\n","(1, 2): 'R',\n","(2, 1): 'R',\n","(2, 2): 'R',\n","(2, 3): 'U',\n","}\n","print_policy(policy, grid)\n","# initialize V(s) and returns\n","V = {}\n","returns = {} # dictionary of state -> list of returns we've received\n","states = grid.all_states()\n","for s in states:\n","    if s in grid.actions:\n","        returns[s] = []\n","    else:\n","      # terminal state or state we can't otherwise get to\n","        V[s] = 0"],"execution_count":7,"outputs":[{"output_type":"stream","text":["rewards:\n","---------------------------\n"," 0.00| 0.00| 0.00| 1.00|\n","---------------------------\n"," 0.00| 0.00| 0.00|-1.00|\n","---------------------------\n"," 0.00| 0.00| 0.00| 0.00|\n","---------------------------\n","  R  |  R  |  R  |     |\n","---------------------------\n","  U  |     |  R  |     |\n","---------------------------\n","  U  |  R  |  R  |  U  |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybAPFccVlUGR","executionInfo":{"status":"ok","timestamp":1619592930111,"user_tz":-270,"elapsed":1106,"user":{"displayName":"ali ghandi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgpQfDUUwGAY8UikVPosVH-EO9X3F39efNCaXLmxA=s64","userId":"08717455413485940524"}},"outputId":"f8c88805-f3d3-46d1-e040-9846f4fc0bf5"},"source":["for t in range(200):\n","    states_and_returns = play_game(grid, policy)\n","    seen_states = set()\n","    for s, G in states_and_returns:\n","        if s not in seen_states:\n","            returns[s].append(G)\n","            V[s] = np.mean(returns[s])\n","            seen_states.add(s)\n","\n","print(\"values:\")\n","print_values(V, grid)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["values:\n","---------------------------\n"," 0.81| 0.90| 1.00| 0.00|\n","---------------------------\n"," 0.73| 0.00|-1.00| 0.00|\n","---------------------------\n"," 0.66|-0.81|-0.90|-1.00|\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YnKsN1NnlUGS"},"source":[""],"execution_count":null,"outputs":[]}]}